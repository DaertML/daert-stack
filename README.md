# daert-stack
Stack to deploy LLM based applications in production

# Introduction
The AI Ecosystem is evolving at a much faster pace in the last years; the appearance of the transformer in 2017 has brought a lot of attention (no pun intentend ;)) to the field.

By scaling the amount of compute and data, a new kind of models is emerging; such models could be classified under the category of AGIs (Artificial General Intelligences); even though it seems
like the holy grail, the capabilities that emerge in such models by just giving instructions and examples in a prompt make them generalist entities.

Even though such power is at the reach of hand of everyone thanks to the development of open source models, yet it seems hard to exploit the value that can be generated by such models.

Several business models and use cases are emerging, yet there is lack of a clear map of ideas in terms of the needed components in the ecosystem to bring the LLMs capabilities to a new
way of doing things.

The appearance of proprietary API based models is easing the "goto market" for many enterprises, by prompting such models with different intents and prompts; somehow, there is a need to bring
all the technologies that are emerging in the field into a unified open architecture.

The greatest effort in these terms are the ideas devised by a16z (https://a16z.com/emerging-architectures-for-llm-applications/); a source from which Daert starts adding other components to the equation
to bring the value of 2024s developments in the LLM ecosystem.

At a glance, the proposed "daert-stack" seems complex and overengineered, somehow there is a certain feeling that depending on the use case, the stack can be simplified: its modular design makes it easy
to remove components and add new ones as time and needs evolve.

It can be acknowledged that having a fully integrated platform will require development efforts from the community, as the interaction of many of such components is not trivial or well-defined.
